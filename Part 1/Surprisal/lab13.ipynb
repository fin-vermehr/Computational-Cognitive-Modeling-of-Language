{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## COG403: Problem 3 of Problem Set 1: Surprisal\n",
    "\n",
    "### All 3 problems for Problem Set 1 Due 4 October 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: To edit this notebook, click \"clone\", and it will prompt you to create your own copy of this library. Make sure to create a private library, so others can't see your answers. For more details, see the How-To Guide for Azure Notebooks posted on Quercus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arpa in /anaconda3/lib/python3.6/site-packages (0.1.0b2)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "P(there|hi) = 0.0025\n",
      "P(there|hi) = 0.0025\n",
      "log_p(there|hi) = -2.5984\n",
      "'hi' in demo_model.vocabulary() = 1.0000\n",
      "P(there|well hi) != 0.0025\n"
     ]
    }
   ],
   "source": [
    "# This installs a Python library called arpa, which is used for loading arpa format language files.\n",
    "# For more information, see: https://pypi.org/project/arpa/\n",
    "# Run this cell before running other cells in this notebook that use the arpa library.\n",
    "\n",
    "!pip install arpa\n",
    "import arpa\n",
    "\n",
    "# Here are some examples of how to use arpa:\n",
    "\n",
    "demo_model = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "\n",
    "# demo_model.p will give you the conditional probability of the last item given what came before\n",
    "print(\"P(there|hi) = {:.4f}\".format(demo_model.p([\"hi\", \"there\"])))\n",
    "\n",
    "# You can pass a list of terms or a string (arpa will automatically split on spaces).\n",
    "print(\"P(there|hi) = {:.4f}\".format(demo_model.p(\"hi there\")))\n",
    "\n",
    "# demo_model.log_p will give you log probabilities\n",
    "print(\"log_p(there|hi) = {:.4f}\".format(demo_model.log_p([\"hi\", \"there\"])))\n",
    "\n",
    "# demo_model.vocabulary() will return the vocabulary of the language model\n",
    "print(\"'hi' in demo_model.vocabulary() = {:.4f}\".format(\"hi\" in demo_model.vocabulary()))\n",
    "\n",
    "# For this problem set, the arpa models are bigram models. Arpa models will not raise an error\n",
    "# when passed trigrams, but the probabilities are not correct. It actually returns the bigram\n",
    "# probability of the last two tokens in the input.\n",
    "print(\"P(there|well hi) != {:.4f}\".format(demo_model.p([\"well\", \"hi\", \"there\"])))  # same output as demo_model.p([hi\", \"there\"])\n",
    "\n",
    "# Note that all input to the arpa model should be lowercase. The following will raise an error:\n",
    "# demo_model.p([\"Hi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Surprisal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smith and Levy$^1$ explored the shape of the relationship between a word’s predictability in context and how long, on average, a comprehender spends on reading that word. In particular they were interested in the hypothesis that a word’s average reading time might be linear in the surprisal of the word (Hale, 2001; Levy, 2008):\n",
    "\n",
    "$$\\textrm{surprisal}(w_i|\\textrm{Context}) = \\log\\frac{1}{P(w_i|\\textrm{Context})} \\quad\\quad (1)$$\n",
    "\n",
    "or in some other function of the word’s conditional probability. In this assignment, you will investigate this question yourself, using one of the datasets analyzed by Smith and Levy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "Write a function to compute the surprisal of a bigram using a bigram arpa model. In the case of out of vocabulary (OOV) items (words that don't occur in our training corpus), return None.\n",
    "\n",
    "Compute the surprisal of the word \"toast\" in the bigram \"like toast\" using the bigram arpa model trained on the British National Corpus (BNC)$^2$ with smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arpa\n",
    "import numpy as np\n",
    "\n",
    "# model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "# vocab = set(model_with_smoothing.vocabulary())\n",
    "\n",
    "def compute_surprisal(arpa_model, bigram, vocab):\n",
    "    \"\"\"\n",
    "    Return the surprisal of the second word in bigram based on bigram probabilities. Return None when\n",
    "    one of the words in bigram is an OOV word.\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in bigram:\n",
    "        if word not in vocab:\n",
    "            return None\n",
    "\n",
    "    cond_prob = arpa_model.p(bigram)\n",
    "    suprisal = np.log(1 / cond_prob)\n",
    "    \n",
    "    return suprisal\n",
    "\n",
    "# print(compute_surprisal(model_with_smoothing, ['like', 'toast'], vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) \n",
    "\n",
    "Compute the surprisal of the word \"toast\" in the bigram \"like toast\" using a bigram model trained on the BNC without smoothing. Is the surprisal of word \"toast\" based on the smoothing higher or lower than that of the model without smoothing? Explain why you think this is.\n",
    "\n",
    "If it's lower, come up with an example that would have higher surprisal without smoothing than with smoothing. If it's higher, come up with an example of a bigram that would have a lower surprisal without smoothing than with smoothing.  Explain how you came up with that example.\n",
    "\n",
    "Hint: investigate the arpa file to see which bigrams occur in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Smoothing:\n",
      "8.406484890161032\n",
      "With Smoothing:\n",
      "10.058847583914675\n"
     ]
    }
   ],
   "source": [
    "corpus_path = \"data/bnc_10k_no_smoothing.arpa\"\n",
    "\n",
    "model_without_smoothing = arpa.loadf(corpus_path)[0]\n",
    "model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "\n",
    "vocab_without_smoothing = set(model_without_smoothing.vocabulary())\n",
    "vocab_with_smoothing = set(model_with_smoothing.vocabulary())\n",
    "\n",
    "\n",
    "# # print(vocab)\n",
    "\n",
    "print(\"Without Smoothing:\")\n",
    "print(compute_surprisal(model_without_smoothing, ['and', 'toast'], vocab_without_smoothing))\n",
    "print(\"With Smoothing:\")\n",
    "print(compute_surprisal(model_with_smoothing, ['and', 'toast'], vocab_with_smoothing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Surprisal and Reading Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)\n",
    "\n",
    "Write a function to load in the Brown Corpus$^3$ annotated with reading times.\n",
    "\n",
    "In `data/brown_reading_times.csv`, you can access the Smith and Levy$^1$ self-paced reading dataset. This dataset derives from each subject in the experiment reading a number of several-hundred-word passages selected from the\n",
    "Brown corpus. This dataset is presented in tabular format, with one reading-time measurement per row and with the following columns:\n",
    "\n",
    " * The **word** that was read;\n",
    " * A **code** that uniquely identifies the word/context pair;\n",
    " * The identifier for the **subject** in the experiment from which the reading-time measurement was taken;\n",
    " * **text_id**, which is the identifier for the text from the Brown corpus that was being read;\n",
    " * **text_pos**, which is the word number in the text selection that was being read;\n",
    " * **word_in_exp** is the word number in the experiment for the particular subject;\n",
    " * The **time** in milliseconds that the word in question was visible on-screen during the subject’s reading. (Remember, in self-paced reading this is the time elapsed between the subject pressing a button/key to reveal the word, and the subject pressing the button/key again to mask that word and reveal the next word.)\n",
    "\n",
    "Take a look at the function `get_sentences_and_reading_times` in `provided_functions.py`. Run this function on `data/brown_reading_times.csv`.\n",
    "\n",
    "Write a function `get_reading_times_and_bigrams` to generate a list of bigrams and reading times for the second word in the bigram. Run it on the sentences and reading times returned by `get_sentences_and_reading_times`. Use the BNC at `data/bnc_10k.txt` as your train corpus (this is used to compute bigram counts for thresholding as described in the docstring for `get_reading_times_and_bigrams` below).\n",
    "\n",
    "Print the first 10 bigrams you generate as well as their associated reading times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'buffeted'), ('by', 'swirling'), ('swirling', 'winds'), ('winds', 'the'), ('the', 'little'), ('little', 'green'), ('green', 'biplane'), ('biplane', 'struggled'), ('struggled', 'northward'), ('northward', 'between')]\n",
      "[723.76, 405.26, 367.21, 379.89, 339.24, 418.62, 351.24, 326.62, 771.31, 471.44]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('as', 'a'),\n",
       "  ('to', 'the'),\n",
       "  ('in', 'the'),\n",
       "  ('<s>', 'he'),\n",
       "  ('as', 'the'),\n",
       "  ('<s>', 'a'),\n",
       "  ('<s>', 'the'),\n",
       "  ('of', 'a'),\n",
       "  ('<s>', 'and'),\n",
       "  ('on', 'the'),\n",
       "  ('of', 'the'),\n",
       "  ('for', 'the'),\n",
       "  ('and', 'the'),\n",
       "  ('<s>', 'but'),\n",
       "  ('with', 'the'),\n",
       "  ('<s>', 'they'),\n",
       "  ('<s>', 'it'),\n",
       "  ('at', 'the'),\n",
       "  ('one', 'of'),\n",
       "  ('with', 'a'),\n",
       "  ('in', 'a'),\n",
       "  ('number', 'of'),\n",
       "  ('<s>', 'she'),\n",
       "  ('for', 'a'),\n",
       "  ('to', 'have'),\n",
       "  ('<s>', 'what'),\n",
       "  ('<s>', 'for'),\n",
       "  ('on', 'a'),\n",
       "  ('<s>', 'this'),\n",
       "  ('will', 'be'),\n",
       "  ('<s>', 'in'),\n",
       "  ('to', 'be'),\n",
       "  ('the', 'same'),\n",
       "  ('all', 'the'),\n",
       "  ('into', 'the'),\n",
       "  ('<s>', 'as'),\n",
       "  ('<s>', 'there'),\n",
       "  ('<s>', 'we'),\n",
       "  ('<s>', 'you'),\n",
       "  ('by', 'the'),\n",
       "  ('from', 'the'),\n",
       "  ('to', 'a'),\n",
       "  ('and', 'a'),\n",
       "  ('be', 'in'),\n",
       "  ('it', '<\\\\s>'),\n",
       "  ('have', 'a'),\n",
       "  ('<s>', 'that'),\n",
       "  ('be', 'the'),\n",
       "  ('<s>', 'so'),\n",
       "  ('may', 'be'),\n",
       "  ('that', 'the'),\n",
       "  ('go', 'to'),\n",
       "  ('<s>', 'i'),\n",
       "  ('have', 'to'),\n",
       "  ('<s>', 'if'),\n",
       "  ('would', 'be'),\n",
       "  ('<s>', 'no'),\n",
       "  ('be', 'a'),\n",
       "  ('<s>', 'oh')],\n",
       " [506.53,\n",
       "  517.78,\n",
       "  340.05,\n",
       "  243.19,\n",
       "  322.56,\n",
       "  485.66,\n",
       "  245.44,\n",
       "  278.26,\n",
       "  329.12,\n",
       "  405.28,\n",
       "  305.16,\n",
       "  352.42,\n",
       "  230.53,\n",
       "  258.87,\n",
       "  234.37,\n",
       "  416.19,\n",
       "  382.8,\n",
       "  191.93,\n",
       "  284.69,\n",
       "  226.01,\n",
       "  416.11,\n",
       "  226.96,\n",
       "  336.42,\n",
       "  260.12,\n",
       "  424.84,\n",
       "  320.82,\n",
       "  156.05,\n",
       "  316.65,\n",
       "  237.41,\n",
       "  413.56,\n",
       "  261.42,\n",
       "  356.97,\n",
       "  450.88,\n",
       "  152.31,\n",
       "  284.48,\n",
       "  228.4,\n",
       "  132.15,\n",
       "  340.04,\n",
       "  284.05,\n",
       "  136.88,\n",
       "  157.29,\n",
       "  328.62,\n",
       "  181.9,\n",
       "  394.57,\n",
       "  152.06,\n",
       "  205.02,\n",
       "  296.99,\n",
       "  180.07,\n",
       "  266.68,\n",
       "  258.7,\n",
       "  237.12,\n",
       "  318.44,\n",
       "  123.35,\n",
       "  346.93,\n",
       "  287.9,\n",
       "  319.97,\n",
       "  248.58,\n",
       "  221.02,\n",
       "  276.44])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from provided_functions import read_sentences_and_reading_times\n",
    "import random \n",
    "data = read_sentences_and_reading_times('data/brown_reading_times.csv')\n",
    "\n",
    "sentences = data[0]\n",
    "reading_times = data[1]\n",
    "train_corpus = open('data/bnc_10k.txt', 'r')\n",
    "\n",
    "#Note: I am not sure what format you want the train_corpus in. I tried us\n",
    "\n",
    "def get_reading_times_and_bigrams(\n",
    "        sentences, reading_times, train_corpus, bigram_threshold=75, max_bigrams=500):\n",
    "    \"\"\"\n",
    "    sentences: list of list of str -- each list is a sentence, and each str is a word\n",
    "    reading_times: list of list of float -- each list is a sentence, and each str is the reading\n",
    "        time for a word\n",
    "    train_corpus: the corpus to use to determine bigram counts for putting a threshold on bigrams\n",
    "    bigram_threshold: the minimum number of times a bigram must occur in train_corpus in order\n",
    "        to be included in the result.\n",
    "    max_bigrams: int -- the maximum number of bigrams and reading times to return\n",
    "    \n",
    "    Return two lists, one containing bigrams, and one containing reading times associated with\n",
    "    the second word in the bigram. Make sure to:\n",
    "        1. Include each bigram only once. For example, even if the bigram (\"i\", \"like\")\n",
    "           occurs 500 times in train_corpus with different reading times, it should only occur\n",
    "           once in the bigram list in the result. Randomly select which reading time to use.\n",
    "        2. Return max_bigrams bigrams or fewer. If there are more than max_bigrams in the sentences,\n",
    "           return 500 randomly selected bigrams.\n",
    "        3. Skip bigrams that occur in train_corpus fewer than bigram_threshold times.\n",
    "        4. Pad sentences with beginning of sentence and end of sentence tokens (\"<s>\" and \"<\\s>\").\n",
    "            For example in the sentence [\"i\", \"like\", toast\"], you should consider the bigrams (\"<s>\", \"i\")\n",
    "            and (\"toast\", \"<\\s>\") in addition to (\"i\", \"like\") and (\"like\", \"toast\").\n",
    "    \"\"\"    \n",
    "    bigram_dict = dict()\n",
    "    \n",
    "    first_ten_bigrams = []\n",
    "    first_ten_times = []\n",
    "    \n",
    "    for index in range(len(sentences)):\n",
    "        reading_time = reading_times[index]\n",
    "        sentence = sentences[index]\n",
    "        \n",
    "        for word_index in range(len(sentence)):\n",
    "            if word_index == 0:\n",
    "                bigram = ('<s>', sentence[word_index])\n",
    "            elif word_index == len(sentence) - 1:\n",
    "                bigram = (sentence[word_index], '<\\s>')\n",
    "            else:\n",
    "                bigram = (sentence[word_index], sentence[word_index + 1])\n",
    "            \n",
    "            if bigram not in bigram_dict:\n",
    "                bigram_dict[bigram] = [[reading_time[word_index]], 0]\n",
    "            else:\n",
    "                bigram_dict[bigram][0].append(reading_time[word_index])\n",
    "                \n",
    "            if len(first_ten_bigrams) < 10:\n",
    "                first_ten_bigrams.append(bigram)\n",
    "                first_ten_times.append(reading_time[word_index])\n",
    "                \n",
    "\n",
    "    # Note: it was not stated what format we want the train_corpus in. Hope this works!\n",
    "     \n",
    "    lines = list(train_corpus)\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.split(' ')[:-1]\n",
    "        for word_index in range(len(line)):\n",
    "            if word_index == 0:\n",
    "                bigram = ('<s>', line[word_index])\n",
    "            elif word_index == len(line) - 1:\n",
    "                bigram = (line[word_index], '<\\s>')\n",
    "            else:\n",
    "                bigram = (line[word_index], line[word_index + 1])\n",
    "\n",
    "            if bigram in bigram_dict:\n",
    "                bigram_dict[bigram][1] += 1\n",
    "\n",
    "    bigram_list = []\n",
    "    reading_time_list = []\n",
    "    \n",
    "    for bigram in bigram_dict:\n",
    "        if (bigram_dict[bigram][1] >= bigram_threshold):\n",
    "            \n",
    "            bigram_list.append(bigram)\n",
    "            random_index = random.randint(0, len(bigram_dict[bigram][0]) - 1)\n",
    "            reading_time_list.append(bigram_dict[bigram][0][random_index])\n",
    "    \n",
    "    print(first_ten_bigrams)\n",
    "    print(first_ten_times)\n",
    "    \n",
    "    final_bigram_list = []\n",
    "    final_reading_list = []\n",
    "    \n",
    "    if len(bigram_list) > max_bigrams:\n",
    "        for i in range(max_bigrams):\n",
    "            random_index = random.randint(0, len(bigram_list) - 1)\n",
    "            final_bigram_list.append(bigram_list[random_index])\n",
    "            final_reading_list.append(reading_time_list[random_index])\n",
    "    \n",
    "            del bigram_list[random_index]\n",
    "            del reading_time_list[random_index]\n",
    "\n",
    "        return final_bigram_list, final_reading_list\n",
    "    return bigram_list, reading_time_list    \n",
    "\n",
    "get_reading_times_and_bigrams(sentences, reading_times, train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\n",
    "\n",
    "Use the BNC with smoothing arpa model, and the `compute_surprisal` function defined in part a to compute the surprisal of each bigram returned by `get_reading_times_and_bigrams` in part c.\n",
    "\n",
    "Use `matplotlib` to generate a scatter plot of surprisal vs. reading time for bigrams in the Brown Corpus.\n",
    "\n",
    "Use `scipy.stats.pearsonr` to compute the linear correlation between surprisal and reading time and print the results.\n",
    "\n",
    "Based on your results, what is the relationship between surprisal and reading time? Explain why you think this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'buffeted'), ('by', 'swirling'), ('swirling', 'winds'), ('winds', 'the'), ('the', 'little'), ('little', 'green'), ('green', 'biplane'), ('biplane', 'struggled'), ('struggled', 'northward'), ('northward', 'between')]\n",
      "[723.76, 405.26, 367.21, 379.89, 339.24, 418.62, 351.24, 326.62, 771.31, 471.44]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111845710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.0230990047324023, 0.8633508967043587)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "data = read_sentences_and_reading_times('data/brown_reading_times.csv')\n",
    "\n",
    "sentences = data[0]\n",
    "reading_times = data[1]\n",
    "\n",
    "train_corpus = open('data/bnc_10k.txt', 'r')\n",
    "\n",
    "model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "vocab = set(model_with_smoothing.vocabulary())\n",
    "\n",
    "\n",
    "times_bigrams = get_reading_times_and_bigrams(sentences, reading_times, train_corpus)\n",
    "\n",
    "bigrams = times_bigrams[0]\n",
    "reading_times = times_bigrams[1]\n",
    "\n",
    "surprisal_list = []\n",
    "reading_list = []\n",
    "\n",
    "for index in range(len(bigrams)):\n",
    "    bigram = list(bigrams[index])\n",
    "    surprisal = compute_surprisal(model_with_smoothing, bigram, vocab)\n",
    "\n",
    "    if surprisal is not None:\n",
    "        reading_list.append(reading_times[index])\n",
    "        surprisal_list.append(surprisal)\n",
    "\n",
    "plt.scatter(surprisal_list, reading_list)\n",
    "plt.show()\n",
    "print(scipy.stats.pearsonr(surprisal_list, reading_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question (d) Response:\n",
    "My calculated correlation coefficient between surprisal and reading time was -0.0972, so there is very little negative correlation between the two, and the p value is very high (0.94), thus we are not very confident in our results. In the end, there's not much we can say about the correlation, it seems pretty uncorrelated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)\n",
    "\n",
    "Using the same bigrams returned by `get_reading_times_and_bigrams` from part c, compute surprisal based on the BNC model **without** smoothing.\n",
    "\n",
    "Generate a scatter plot and compute the linear correlation for the results without smoothing, as you did in part d. Do your results differ from the results in part d? If so, explain why, and if not, explain why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'buffeted'), ('by', 'swirling'), ('swirling', 'winds'), ('winds', 'the'), ('the', 'little'), ('little', 'green'), ('green', 'biplane'), ('biplane', 'struggled'), ('struggled', 'northward'), ('northward', 'between')]\n",
      "[723.76, 405.26, 367.21, 379.89, 339.24, 418.62, 351.24, 326.62, 771.31, 471.44]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2eb98d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.24713785911988703, 0.06144207143527606)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "data = read_sentences_and_reading_times('data/brown_reading_times.csv')\n",
    "\n",
    "sentences = data[0]\n",
    "reading_times = data[1]\n",
    "\n",
    "train_corpus = open('data/bnc_10k.txt', 'r')\n",
    "\n",
    "model_without_smoothing = arpa.loadf(\"data/bnc_10k_no_smoothing.arpa\")[0]\n",
    "vocab = set(model_without_smoothing.vocabulary())\n",
    "\n",
    "\n",
    "times_bigrams = get_reading_times_and_bigrams(sentences, reading_times, train_corpus)\n",
    "\n",
    "bigrams = times_bigrams[0]\n",
    "reading_times = times_bigrams[1]\n",
    "\n",
    "surprisal_list = []\n",
    "reading_list = []\n",
    "\n",
    "for index in range(len(bigrams)):\n",
    "    bigram = list(bigrams[index])\n",
    "    surprisal = compute_surprisal(model_without_smoothing, bigram, vocab)\n",
    "\n",
    "    if surprisal is not None:\n",
    "        reading_list.append(reading_times[index])\n",
    "        surprisal_list.append(surprisal)\n",
    "\n",
    "plt.scatter(surprisal_list, reading_list)\n",
    "plt.show()\n",
    "print(scipy.stats.pearsonr(surprisal_list, reading_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear correlation for the two results without smoothing was 0.07 with an even higher p value (0.598), thus we are even less confident about this result than with the smoothed dataset. That being said, it is not actually significaintly different. This is because of the bigram_threshold, which is set to 75, it ensures that only common bigrams are used for surprisal calculations. These common bigrams are all in the unsmoothed data. When we reduce bigram_threshold to 0, our data has two seperate columns, is very different from the smoothed data and has a correlation of 0.02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Surprisal and Concreteness\n",
    "\n",
    "Given the experiments we've done so far, we don't really know if surprisal is connected to semantics. One prominent element of semantics that cognitive scientists have found plays a role in word processing is concreteness. In the next part of the problem, we'll look at the relationship between surprisal and concreteness. To do this, we'll use the Calgary Concreteness data set$^4$, which has several English nouns and their concreteness ratings on a scale from 1 to 5. This dataset is in `data/calgary_concreteness.csv`.  We provide the functions that read in info from this dataset in `provided_functions.py`. Using this data, we can compare the average surprisal of words that are relatively high in concreteness to those that are relatively low in concreteness, to see how concreteness affects reading times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f)\n",
    "\n",
    "Write a function `compute_average_word_surprisal`, which computes the average surprisal for a given word based on `max_bigrams` randomly selected contexts that that word occurs in in the BNC corpus.\n",
    "\n",
    "Use the function `compute_average_word_surprisal` to find the average surprisal for the word *cat*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5901537961723715"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from provided_functions import get_bigram_counts\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def compute_average_word_surprisal(word, bigram_counter, model, max_bigrams=10):\n",
    "    \"\"\"\n",
    "    word: string -- the word to compute average surprisal for\n",
    "    bigram_counter: collections.Counter -- a Counter mapping bigram tuples to frequency in a corpus.\n",
    "                    This can be comptued using the function get_bigram_counts in provided_functions.py\n",
    "    model: arpa model -- an arpa model\n",
    "    max_bigrams: int -- number of sampled bigrams used to compute the average surprisal of word\n",
    "    \n",
    "    Return the average surprisal of a bigram containing word in index 1. For example,\n",
    "    for the word 'cat', we would consider ('my', 'cat') but not ('cat', 'went'). In cases where there\n",
    "    are more than max_bigrams in bigram_counter that contain word in index 0, compute average surprisal\n",
    "    based on max_bigrams randomly selected bigrams.\n",
    "    \"\"\"\n",
    "    surprisal_list = []\n",
    "    vocab = set(model.vocabulary())\n",
    "    \n",
    "    for bigram in bigram_counter:\n",
    "        if bigram[1] == word:\n",
    "            surprisal_list.append(compute_surprisal(model, bigram, vocab))\n",
    "\n",
    "    if len(surprisal_list) <= max_bigrams:\n",
    "        return np.mean(surprisal_list)\n",
    "\n",
    "    else:\n",
    "        final_surprisal_list = []\n",
    "        for i in range(max_bigrams):\n",
    "            random_index = random.randint(0, len(surprisal_list) - 1)\n",
    "            final_surprisal_list.append(surprisal_list[random_index])\n",
    "            del surprisal_list[random_index]\n",
    "            \n",
    "        return np.mean(final_surprisal_list)\n",
    "        \n",
    "bigram_counts = get_bigram_counts('data/bnc_10k.txt')\n",
    "model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "compute_average_word_surprisal('cat', bigram_counts, model_with_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g)\n",
    "\n",
    "Take a look at the files `data/low_concreteness_nouns.txt` and `data/high_concreteness_nouns.txt`. These files each contain a subset of 100 nouns from the Calgary Concreteness data set with low concreteness (< 2.5), high concreteness (> 3.5) respectively. They are the most common nouns of each type based on frequency in the BNC sample.\n",
    "\n",
    "Use `matplotlib` to generate a scatter plot of surprisal vs. concreteness for the low concreteness nouns in `data/low_concreteness_nouns.txt`. You should use `compute_average_word_surprisal` from part f as well as the functions `load_words`, `get_bigram_counts`, and `read_concreteness` defined in `provided_functions.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3012b438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.058374956563435436, 0.5640052006199161)\n"
     ]
    }
   ],
   "source": [
    "from provided_functions import load_words, read_concreteness\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "bigram_counts = get_bigram_counts('data/bnc_10k.txt')\n",
    "model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "\n",
    "\n",
    "words = load_words('data/low_concreteness_nouns.txt')\n",
    "concreteness = read_concreteness('data/calgary_concreteness.csv')\n",
    "\n",
    "surprisal_averages = []\n",
    "concreteness_list = []\n",
    "\n",
    "for index in range(len(words)):\n",
    "    surprisal_averages.append(compute_average_word_surprisal(words[index], bigram_counts, model_with_smoothing))\n",
    "    word_index = concreteness[1].index(words[index])\n",
    "    concreteness_list.append(concreteness[0][word_index])\n",
    "        \n",
    "plt.scatter(surprisal_averages, concreteness_list)\n",
    "plt.show()\n",
    "print(scipy.stats.pearsonr(surprisal_averages, concreteness_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h)\n",
    "\n",
    "Use the same approach that you used in part g to generate a scatter plot of surprisal vs. concreteness the nouns in `data/high_concreteness_nouns.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a353cdfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.30468397377663925, 0.0020550010838876385)\n"
     ]
    }
   ],
   "source": [
    "from provided_functions import load_words, read_concreteness\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "bigram_counts = get_bigram_counts('data/bnc_10k.txt')\n",
    "model_with_smoothing = arpa.loadf(\"data/bnc_10k_with_smoothing.arpa\")[0]\n",
    "\n",
    "\n",
    "words = load_words('data/high_concreteness_nouns.txt')\n",
    "concreteness = read_concreteness('data/calgary_concreteness.csv')\n",
    "\n",
    "surprisal_averages = []\n",
    "concreteness_list = []\n",
    "\n",
    "for index in range(len(words)):\n",
    "    surprisal_averages.append(compute_average_word_surprisal(words[index], bigram_counts, model_with_smoothing))\n",
    "    word_index = concreteness[1].index(words[index])\n",
    "    concreteness_list.append(concreteness[0][word_index])\n",
    "        \n",
    "plt.scatter(surprisal_averages, concreteness_list)\n",
    "plt.show()\n",
    "print(scipy.stats.pearsonr(surprisal_averages, concreteness_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i)\n",
    "\n",
    "What is the relationship between surprisal and concreteness? Is the relationship different for high and low concreteness nouns? Explain why you think this is or is not the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Solution:\n",
    "\n",
    "There seems to be no correlation between the low concreteness nouns and suprisal, but there is a negative correlation between the high concreteness nouns and surprisal, i.e the higher the surprisal, the less suprised someone is, the more concrete the noun is. I have two possible explanations for this:\n",
    "\n",
    "1. Concrete nouns refer to objects we encounter, and see everyday. We are generally more familiar with them, and do not need to think about them as much.\n",
    "2. The frequency of concrete nouns in literature is higher than abstract nouns. Since the surprisal function is dependent on the context of the word, and most context (due to higher frequency) predict concrete nouns, and thus, surprisal is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "$^1$Smith, N. J., & Levy, R. (2013). The effect of word predictability on reading time is logarithmic. Cognition, 128(3), 302-319. doi:10.1016/j.cognition.2013.02.013\n",
    "\n",
    "$^2$The British National Corpus, version 3 (BNC XML Edition). 2007. Distributed by Bodleian Libraries, University of Oxford, on behalf of the BNC Consortium. URL: http://www.natcorp.ox.ac.uk/\n",
    "\n",
    "$^3$A Standard Corpus of Present-Day Edited American English, for use with Digital Computers (Brown). 1964, 1971, 1979. Compiled by W. N. Francis and H. Kučera. Brown University. Providence, Rhode Island.\n",
    "\n",
    "$^4$Pexman, P. M., Heard, A., Lloyd, E., & Yap, M. J. (2016). The Calgary semantic decision project: Concrete/abstract decision data for 10,000 English words. Behavior Research Methods, 49(2), 407-417. doi:10.3758/s13428-016-0720-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
